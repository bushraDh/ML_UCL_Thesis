{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas numpy torchvision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset, random_split\n",
    "import numpy as np\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import matplotlib.pyplot as plt\n",
    "from CNNs.modelsLSTM import AstroNet,RNN\n",
    "from analysis import plot_circles_on_image,pixel_distance,Metrics,epoch_metrics,error_calc\n",
    "import copy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train dynamic models to find the CoB and CoM of a celectial object\n",
    "## Objects:\n",
    "- Mars\n",
    "- Asteroid itokawa \n",
    "## Models:\n",
    "- CNN - RNN\n",
    "- AstroNet (CNN-LSTM) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Itokawa: \n",
    "Uncomment this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from asteroids.generate_datasetSQ import CustomDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Mars:\n",
    "Uncomment this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Mars.generate_datasetSQ import CustomDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "train_dataset = torch.load('train_datasetSQ.pth')\n",
    "val_dataset= torch.load('val_datasetSQ.pth')\n",
    "test_dataset = torch.load('test_datasetSQ.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data loaders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True)\n",
    "val_loader =   DataLoader(val_dataset, batch_size=20, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=22, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(num_epochs, train_losses, val_losses, val_distances):\n",
    "   epochs = range(1, num_epochs + 1)\n",
    "   plt.rcParams.update({'font.size': 24})\n",
    "   dark_grey= '#3b3b3b'\n",
    "   # Plotting all the losses\n",
    "   plt.figure(figsize=(12, 6))\n",
    "\n",
    "   plt.scatter(epochs, train_losses, label='Training Loss')\n",
    "   plt.scatter(epochs, val_losses, label='Validation Loss')\n",
    "   plt.xlabel('Epochs', color=dark_grey)\n",
    "   plt.ylabel('Loss', color=dark_grey)\n",
    "   plt.legend(labelcolor=dark_grey)\n",
    "   plt.title('Training and Validation Loss', color=dark_grey)\n",
    "   plt.tight_layout()\n",
    "#    plt.savefig(\"pics//asteroids//Valtrain_loss_ast_COB3.pdf\", format=\"pdf\")\n",
    "   plt.show()\n",
    "\n",
    "   # Plotting all the distances\n",
    "   plt.figure(figsize=(12, 6))\n",
    "\n",
    "   plt.scatter(epochs, val_distances, label='Validation Distance', color='green')\n",
    "   plt.xlabel('Epochs', color=dark_grey)\n",
    "   plt.ylabel('Distance', color=dark_grey)\n",
    "   plt.legend( labelcolor=dark_grey)\n",
    "   plt.title('Pixel Distance', color=dark_grey)\n",
    "   plt.tight_layout()\n",
    "#    plt.savefig(\"pics//asteroids//Valdistance_ast_COB3.pdf\", format=\"pdf\")\n",
    "   plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(outputs, targets):\n",
    "    total_distance = 0\n",
    "    for output, target in zip(outputs, targets):\n",
    "        distance = ((target[0] - output[0]) ** 2 + (target[1] - output[1]) ** 2) ** 0.5\n",
    "        total_distance += distance\n",
    "    return total_distance / len(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(valloader, dataloader, model, device='cpu'):\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.MSELoss()\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=3)\n",
    "\n",
    "    patience = 7\n",
    "    best_loss = float('inf')\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    no_improvement_counter = 0\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_distances = []\n",
    "    accuracies = []\n",
    "    metrics_history = {'MAE': [], 'MSE': [], 'RMSE': [], 'R-squared': []}\n",
    "\n",
    "    num_epochs = 80\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"##### epoch {} : #####\".format(epoch + 1))\n",
    "\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        tot = 0.0\n",
    "        b = 0.0\n",
    "\n",
    "        for inputs, targets in tqdm(dataloader):\n",
    "            tot += dataloader.batch_size\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            # Ensure outputs have the correct shape (batch_size, num_classes)\n",
    "            t=targets[:, -1, :]\n",
    "            o=outputs[:, -1, :]\n",
    "\n",
    "            loss = criterion(outputs, targets)  # Use the last label in the sequence\n",
    "            loss.backward()\n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
    "\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            b += 1.0\n",
    "            if b % 1000 == 0:\n",
    "                print(\"batch: {}: Running Loss  {:.4f}\".format(b, running_loss / b))\n",
    "                # print(f'Outputs : {o[:3]}')  # Should be (batch_size, output_size)\n",
    "                # print(f'Labels : {t[:3]}')  # Should be (batch_size,)\n",
    "\n",
    "        train_loss = running_loss / len(dataloader)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        validation_loss = 0.0\n",
    "        total_distance = 0.0\n",
    "        counter = 0.0\n",
    "        Error = 0.0\n",
    "        metrics = {'MAE': 0.0, 'MSE': 0.0, 'RMSE': 0.0, 'R-squared': 0.0, 'count': 0}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, y in valloader:\n",
    "                x_val, y_val = x.to(device), y.to(device)\n",
    "                val_result = model(x_val)\n",
    "                lossv = criterion(val_result, y_val)  # Use the last label in the sequence\n",
    "                validation_loss += lossv.item()\n",
    "                d, c = pixel_distance(val_result[:, -1, :], y_val[:, -1, :])\n",
    "                Error += error_calc(val_result[:, -1, :], y_val[:, -1, :])\n",
    "                total_distance += d.item()\n",
    "                counter += c\n",
    "                Metrics(metrics, val_result[:, -1, :], y_val[:, -1, :])\n",
    "\n",
    "        avg_val_loss = validation_loss / len(valloader)\n",
    "        avg_val_distance = total_distance / len(valloader)\n",
    "        accuracy = 100 * (counter / len(valloader.dataset))\n",
    "        Error /= len(valloader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        val_distances.append(avg_val_distance)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}\\n\"\n",
    "              f\"Validation Distance: {avg_val_distance:.4f}, Validation Accuracy: {accuracy:.4f}, Error: {Error:.4f}\")\n",
    "        epoch_metric = epoch_metrics(metrics)\n",
    "        for metric, value in epoch_metric.items():\n",
    "            metrics_history[metric].append(value)\n",
    "        scheduler.step(avg_val_loss)\n",
    "        scheduler.get_last_lr()\n",
    "        if avg_val_loss < best_loss:\n",
    "            best_loss = avg_val_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            no_improvement_counter = 0\n",
    "        else:\n",
    "            no_improvement_counter += 1\n",
    "            if no_improvement_counter >= patience:\n",
    "                print(\"Early stopping triggered\")\n",
    "                num_epochs = epoch + 1\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    plot_results(num_epochs, train_losses, val_losses, val_distances)\n",
    "    return model, train_losses, val_losses, val_distances, metrics_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test(model, testloader, device='cpu'):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    num_epochs = 5\n",
    "    criterion = nn.MSELoss()\n",
    "    test_losses = []\n",
    "    test_distances = []\n",
    "    accuracies = []\n",
    "    Error = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"##### epoch {} : #####\".format(epoch + 1))\n",
    "        metrics = {'MAE': 0.0, 'MSE': 0.0, 'RMSE': 0.0, 'R-squared': 0.0, 'count': 0}\n",
    "\n",
    "        test_loss = 0.0\n",
    "        total_distance = 0.0\n",
    "        counter = 0.0\n",
    "        n = 0.0\n",
    "        with torch.no_grad():\n",
    "            for x, y in testloader:\n",
    "                x_test, y_test = x.to(device), y.to(device)\n",
    "                test_result = model(x_test)\n",
    "                losst = criterion(test_result, y_test)\n",
    "                test_loss += losst.item()\n",
    "                d, c = pixel_distance(test_result[:, -1, :], y_test[:, -1, :])\n",
    "                total_distance += d\n",
    "                counter += c\n",
    "                Metrics(metrics, test_result[:, -1, :], y_test[:, -1, :])\n",
    "                if n % 50 == 0:\n",
    "                    plot_circles_on_image(x_test[0, -1, :], test_result[0, -1, :], y_test[0, -1, :])\n",
    "                n += 1.0\n",
    "\n",
    "                Error += error_calc(test_result[:, -1, :], y_test[:, -1, :])\n",
    "                counter += c\n",
    "\n",
    "        Error /= len(testloader)\n",
    "        avg_test_loss = test_loss / len(testloader)\n",
    "        avg_test_distance = total_distance / len(testloader)\n",
    "        accuracy = 100 * (counter / len(testloader.dataset))\n",
    "        test_losses.append(avg_test_loss)\n",
    "        test_distances.append(avg_test_distance)\n",
    "        accuracies.append(accuracy)\n",
    "        print(f\"Test Loss: {avg_test_loss:.4f}, Test Distance: {avg_test_distance:.4f}, Error: {Error:.4f}\")\n",
    "        epoch_metric = epoch_metrics(metrics)\n",
    "\n",
    "    return test_losses, test_distances, accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"** GPU **\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"** CPU **\")\n",
    "\n",
    "# LTSM_model =RNN1()\n",
    "LSTM_model= CNNLSTM()\n",
    "model,train_losses ,val_losses ,val_distances,val_metrics =train(test_loader,train_loader,LSTM_model,device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, 'mars_models//model_LSTM_COB.pth')\n",
    "# print(\"Model paths is saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and test the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = torch.load('mars_models//model_LSTM_COB.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test(model_test, test_loader, device='cpu')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
