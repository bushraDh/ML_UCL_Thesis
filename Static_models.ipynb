{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas numpy torchvision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset, random_split\n",
    "import numpy as np\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from Mars.generate_dataset import CustomDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from CNNs.models import CNN, ResNet\n",
    "from CNNs.Baseline import LinearReg\n",
    "from analysis import plot_circles_on_image,pixel_distance,Metrics,epoch_metrics,error_calc\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train static models to find the CoB and CoM of a celectial object\n",
    "## Objects:\n",
    "- Mars\n",
    "## Models:\n",
    "- Linear Regression \n",
    "- CNN\n",
    "- ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "train_dataset = torch.load('train_dataset.pth')\n",
    "val_dataset= torch.load('val_dataset.pth')\n",
    "test_dataset = torch.load('test_dataset.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=50, shuffle=True)\n",
    "val_loader =   DataLoader(val_dataset, batch_size=20, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting fuction \n",
    "def plot_results(num_epochs, train_losses, val_losses, val_distances):\n",
    "   epochs = range(1, num_epochs + 1)\n",
    "   plt.rcParams.update({'font.size': 24})\n",
    "   dark_grey= '#3b3b3b'\n",
    "   # Plotting all the losses\n",
    "   plt.figure(figsize=(12, 6))\n",
    "   plt.scatter(epochs, train_losses, label='Training Loss')\n",
    "   plt.scatter(epochs, val_losses, label='Validation Loss')\n",
    "   plt.xlabel('Epochs', color=dark_grey)\n",
    "   plt.ylabel('Loss', color=dark_grey)\n",
    "   plt.legend(labelcolor=dark_grey)\n",
    "   plt.title('Training and Validation Loss', color=dark_grey)\n",
    "   plt.tight_layout()\n",
    "#    plt.savefig(\"pics//asteroids//Valtrain_loss_ast_COB3.pdf\", format=\"pdf\")\n",
    "   plt.show()\n",
    "\n",
    "   # Plotting all the distances\n",
    "   plt.figure(figsize=(12, 6))\n",
    "\n",
    "   plt.scatter(epochs, val_distances, label='Validation Distance', color='green')\n",
    "   plt.xlabel('Epochs', color=dark_grey)\n",
    "   plt.ylabel('Distance', color=dark_grey)\n",
    "   plt.legend( labelcolor=dark_grey)\n",
    "   plt.title('Pixel Distance', color=dark_grey)\n",
    "   plt.tight_layout()\n",
    "#    plt.savefig(\"pics//asteroids//Valdistance_ast_COB3.pdf\", format=\"pdf\")\n",
    "   plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train function \n",
    "def train(valloader,dataloader,model,device='cpu'):\n",
    "    # Instantiate the model\n",
    "    # Define an optimizer and loss function\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001) \n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=3)\n",
    "\n",
    "    patience = 10  # Number of epochs to wait for improvement before stopping\n",
    "    best_loss = float('inf')\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    no_improvement_counter = 0\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_distances = []\n",
    "    accuracies = []\n",
    "    metrics_history = {'MAE': [], 'MSE': [], 'RMSE': [], 'R-squared': []}\n",
    "\n",
    "    num_epochs = 80  # Set the number of epochs as required\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"##### epoch {} : #####\".format(epoch+1))\n",
    "\n",
    "        model.train()  # Set the model to training mode\n",
    "        running_loss,tot = 0.0,0.0\n",
    "        b=0.\n",
    "\n",
    "        for inputs, targets in dataloader:\n",
    "            tot += dataloader.batch_size  \n",
    "            inputs=inputs.to(device)\n",
    "            targets=targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss+= loss.item()\n",
    "            b += 1.0\n",
    "            if  b % 500 == 0:\n",
    "                print(\"batch: {}: Running Loss  {:.4f}\".format(b,running_loss/b))\n",
    "            \n",
    "        train_loss = running_loss / (len(dataloader))\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        \n",
    "        validation_loss = 0.0\n",
    "        total_distance = 0.0\n",
    "        counter=0.0\n",
    "        Error=0.0\n",
    "        metrics = {'MAE': 0.0, 'MSE': 0.0, 'RMSE': 0.0, 'R-squared': 0.0,'count': 0}\n",
    "\n",
    "        n=0.0\n",
    "        with torch.no_grad():\n",
    "            for x, y in valloader:\n",
    "                x_val, y_val = x.to(device), y.to(device)\n",
    "                val_result = model(x_val)\n",
    "                lossv = criterion(val_result, y_val)\n",
    "                validation_loss += lossv.item()\n",
    "                d, c = pixel_distance(val_result, y_val)\n",
    "                Error+= error_calc(val_result, y_val)\n",
    "                total_distance += d.item()\n",
    "                counter += c\n",
    "                Metrics(metrics, val_result, y_val)\n",
    "               \n",
    "\n",
    "        avg_val_loss = validation_loss / len(valloader)\n",
    "        avg_val_distance = total_distance / len(valloader)\n",
    "        accuracy = 100 * (counter / len(valloader.dataset))\n",
    "        Error/=len(valloader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        val_distances.append(avg_val_distance)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}\\n\" \n",
    "              f\"Validation Distance: {avg_val_distance:.4f}, Validation Accuracy: {accuracy:.4f}, Error: {Error:.4f} \")\n",
    "        epoch_metric = epoch_metrics(metrics)\n",
    "        for metric, value in epoch_metric.items():\n",
    "            metrics_history[metric].append(value)\n",
    "        # Step the learning rate scheduler\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "        # Early stopping and saving the best model\n",
    "        if avg_val_loss < best_loss:\n",
    "            best_loss = avg_val_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            no_improvement_counter = 0\n",
    "        else:\n",
    "            no_improvement_counter += 1\n",
    "            if no_improvement_counter >= patience:\n",
    "                print(\"Early stopping triggered\")\n",
    "                num_epochs=epoch+1\n",
    "                break\n",
    "\n",
    "    # Load the best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    plot_results(num_epochs,train_losses,val_losses,val_distances)\n",
    "    return model, train_losses ,val_losses ,val_distances,metrics_history \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test(model, testloader, device='cpu'):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    num_epochs = 5 \n",
    "    criterion = nn.MSELoss()\n",
    "    test_losses = []\n",
    "    test_distances = []\n",
    "    accuracies = []\n",
    "    Error=0.0\n",
    " # Set the number of epochs as required\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"##### epoch {} : #####\".format(epoch+1))\n",
    "        metrics = {'MAE': 0.0, 'MSE': 0.0, 'RMSE': 0.0, 'R-squared': 0.0, 'count': 0}\n",
    "        \n",
    "        test_loss = 0.0\n",
    "        total_distance = 0.0\n",
    "        counter = 0.0\n",
    "        n=0.0\n",
    "        with torch.no_grad():\n",
    "            for x, y in testloader:\n",
    "                x_test, y_test = x.to(device), y.to(device)\n",
    "                test_result = model(x_test)\n",
    "                losst = criterion(test_result, y_test)\n",
    "                test_loss += losst.item()\n",
    "                d, c = pixel_distance(test_result, y_test)\n",
    "                total_distance += d\n",
    "                counter += c\n",
    "                Metrics(metrics, test_result, y_test)\n",
    "                if n%500==0 and c/(testloader.batch_size)>= 0.95:\n",
    "                    plot_circles_on_image(x_test[0], test_result[0], y_test[0])\n",
    "                n+=1.0  \n",
    "\n",
    "                Error+= error_calc(test_result, y_test)\n",
    "                counter += c              \n",
    "\n",
    "        Error/=len(testloader)\n",
    "        avg_test_loss = test_loss / len(testloader)\n",
    "        avg_test_distance = total_distance / len(testloader)\n",
    "        accuracy = 100 * (counter / len(testloader.dataset))\n",
    "        test_losses.append(avg_test_loss)\n",
    "        test_distances.append(avg_test_distance)\n",
    "        accuracies.append(accuracy)\n",
    "        print(f\"Test Loss: {avg_test_loss:.4f}, Test Distance: {avg_test_distance:.4f}, Error: {Error:.4f} \")\n",
    "        epoch_metric = epoch_metrics(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"** GPU **\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"** CPU **\")\n",
    "\n",
    "model=CNN()\n",
    "model,train_losses ,val_losses ,val_distances,val_metrics =train(val_loader,train_loader,model,device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, 'model_CNN2_COB_COMM.pth')\n",
    "# print(\"Model paths is saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and test the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model= torch.load('model_CNN2_CoM.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test(test_model, test_loader, device='cpu')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
